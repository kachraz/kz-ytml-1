# ????????????????????????????????????????????????????????????????????????????????
# Running the same tests with LiteLLM
# ????????????????????????????????????????????????????????????????????????????????

# --- Imports ---

import os

from dotenv import load_dotenv
from litellm import completion

from src.utz import header1

# --- Load the envpussy --
load_dotenv("src/.env")
SA_T = os.getenv("SAO")

# --- Main File Function ---


def s2_file():
    header1("S2 File Function")


# === Sub Functions ===

# Litellm Example from docs
# https://docs.sambanova.ai/cloud/docs/integrations/litellm#litellm

def lite1():
    header1("LiteLLM Example from SN docs")

    os.environ['SAMBANOVA_API_KEY'] = "SA_T"
    response = completion(
        model="Meta-Llama-3.2-3B-Instruct",
        messages=[
            {
                "role": "user",
                "content": "What do you know about sambanova.ai. Give your response in json format",
            }
        ],
        max_tokens=10,
        response_format={"type": "json_object"},
        stop=["\n\n"],
        temperature=0.2,
        top_p=0.9,
        tool_choice="auto",
        tools=[],
        user="user",
    )
    print(response)
